version: '3.8'

services:
  # Nginx for serving static files and as a reverse proxy
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/conf.d:/etc/nginx/conf.d
      - ./nginx/ssl:/etc/nginx/ssl
      - ./frontend/public:/usr/share/nginx/html
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - app
    restart: unless-stopped
    networks:
      - frontend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Application server
  app:
    build:
      context: .
      dockerfile: Dockerfile.production
    environment:
      - PORT=8080
      - HOST=0.0.0.0
      - USE_HTTPS=false
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=${DB_NAME:-registration}
      - DB_USER=${DB_USER:-regapp}
      - DB_PASSWORD=${DB_PASSWORD:-your-secure-password}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - SECRET_KEY=${SECRET_KEY:-your-secure-secret-key}
      - SUMSUB_APP_TOKEN=${SUMSUB_APP_TOKEN}
      - SUMSUB_SECRET_KEY=${SUMSUB_SECRET_KEY}
      - SUMSUB_WEBHOOK_SECRET=${SUMSUB_WEBHOOK_SECRET}
    volumes:
      - ./logs/app:/app/logs
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    networks:
      - frontend
      - backend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      replicas: 2
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure

  # PostgreSQL database
  postgres:
    image: postgres:14-alpine
    environment:
      - POSTGRES_USER=${DB_USER:-regapp}
      - POSTGRES_PASSWORD=${DB_PASSWORD:-your-secure-password}
      - POSTGRES_DB=${DB_NAME:-registration}
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./database/schema.sql:/docker-entrypoint-initdb.d/schema.sql
    ports:
      - "5432:5432"
    networks:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-regapp}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for caching and session storage
  redis:
    image: redis:alpine
    command: redis-server --requirepass ${REDIS_PASSWORD:-your-redis-password}
    volumes:
      - redis-data:/data
    networks:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - "9090:9090"
    networks:
      - monitoring
    restart: unless-stopped

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - grafana-data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3000:3000"
    networks:
      - monitoring
    depends_on:
      - prometheus
    restart: unless-stopped

  # Elasticsearch for log storage
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - logging
    restart: unless-stopped

  # Logstash for log processing
  logstash:
    image: docker.elastic.co/logstash/logstash:7.17.0
    volumes:
      - ./logging/logstash/pipeline:/usr/share/logstash/pipeline
      - ./logs:/logs
    environment:
      - LS_JAVA_OPTS=-Xmx256m -Xms256m
    networks:
      - logging
    depends_on:
      - elasticsearch
    restart: unless-stopped

  # Kibana for log visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - logging
    depends_on:
      - elasticsearch
    restart: unless-stopped

  # Filebeat for log shipping
  filebeat:
    image: docker.elastic.co/beats/filebeat:7.17.0
    volumes:
      - ./logging/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - ./logs:/logs:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    user: root
    networks:
      - logging
    depends_on:
      - elasticsearch
      - logstash
    restart: unless-stopped

  # Backup service
  backup:
    image: postgres:14-alpine
    volumes:
      - ./backups:/backups
      - ./scripts/backup.sh:/backup.sh
    environment:
      - PGHOST=postgres
      - PGUSER=${DB_USER:-regapp}
      - PGPASSWORD=${DB_PASSWORD:-your-secure-password}
      - PGDATABASE=${DB_NAME:-registration}
      - BACKUP_RETENTION_DAYS=7
    entrypoint: ["/bin/sh", "/backup.sh"]
    networks:
      - backend
    depends_on:
      - postgres
    restart: unless-stopped

networks:
  frontend:
  backend:
  monitoring:
  logging:

volumes:
  postgres-data:
  redis-data:
  prometheus-data:
  grafana-data:
  elasticsearch-data:
